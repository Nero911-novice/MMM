import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_absolute_percentage_error
from scipy.optimize import minimize, differential_evolution, LinearConstraint, Bounds
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# ==========================================
# MARKETING MIX MODEL - –û–°–ù–û–í–ù–ê–Ø –ú–û–î–ï–õ–¨
# ==========================================

class MarketingMixModel:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è Marketing Mix Modeling.
    
    –†–µ–∞–ª–∏–∑—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤–ª–∏—è–Ω–∏—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã—Ö –∫–∞–Ω–∞–ª–æ–≤
    –Ω–∞ –±–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫–∏ —Å —É—á–µ—Ç–æ–º —ç—Ñ—Ñ–µ–∫—Ç–æ–≤ –ø–µ—Ä–µ–Ω–æ—Å–∞ (adstock) –∏ –Ω–∞—Å—ã—â–µ–Ω–∏—è (saturation).
    """
    
    def __init__(self, adstock_params=None, saturation_params=None, 
                 regularization='Ridge', alpha=1.0, normalize_features=True):
        self.adstock_params = adstock_params or {}
        self.saturation_params = saturation_params or {}
        self.regularization = regularization
        self.alpha = alpha
        self.normalize_features = normalize_features
        
        self.scaler = StandardScaler() if normalize_features else None
        self.regressor = self._get_regressor()
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
        self.is_fitted = False
        self.feature_names = None
        self.media_channels = None
        self.target_name = None
        
    def _get_regressor(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏."""
        if self.regularization == 'Ridge':
            return Ridge(alpha=self.alpha, fit_intercept=True)
        elif self.regularization == 'Lasso':
            return Lasso(alpha=self.alpha, fit_intercept=True, max_iter=2000)
        elif self.regularization == 'ElasticNet':
            return ElasticNet(alpha=self.alpha, fit_intercept=True, max_iter=2000)
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏: {self.regularization}")
    
    def _apply_adstock(self, media_data, decay_rate=0.5):
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å –ø—Ä–æ—Å—Ç—É—é Adstock —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é."""
        adstocked = np.zeros_like(media_data, dtype=float)
        for i in range(len(media_data)):
            if i == 0:
                adstocked[i] = media_data[i]
            else:
                adstocked[i] = media_data[i] + decay_rate * adstocked[i-1]
        return adstocked
    
    def _apply_saturation(self, media_data, alpha=1.0, gamma=None):
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å Hill Saturation —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—é."""
        if gamma is None:
            gamma = np.median(media_data[media_data > 0]) if np.any(media_data > 0) else 1.0
        
        media_data = np.maximum(media_data, 1e-10)
        gamma = max(gamma, 1e-10)
        
        numerator = np.power(media_data, alpha)
        denominator = np.power(media_data, alpha) + np.power(gamma, alpha)
        denominator = np.maximum(denominator, 1e-10)
        
        return numerator / denominator
    
    def _apply_transformations(self, X_media, fit=False):
        """–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ adstock –∏ saturation –∫ –º–µ–¥–∏–∞-–ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º."""
        X_transformed = X_media.copy()
        
        for channel in X_media.columns:
            # Adstock
            if channel in self.adstock_params:
                decay_rate = self.adstock_params[channel].get('decay', 0.5)
            else:
                decay_rate = 0.5
            
            X_transformed[channel] = self._apply_adstock(X_media[channel].values, decay_rate)
            
            # Saturation
            if channel in self.saturation_params:
                alpha = self.saturation_params[channel].get('alpha', 1.0)
                gamma = self.saturation_params[channel].get('gamma', None)
            else:
                alpha = 1.0
                gamma = None
            
            X_transformed[channel] = self._apply_saturation(X_transformed[channel].values, alpha, gamma)
        
        return X_transformed
    
    def fit(self, X, y):
        """–û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å MMM."""
        if not isinstance(X, pd.DataFrame):
            raise ValueError("X –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å pandas DataFrame")
        
        if len(X) != len(y):
            raise ValueError("–†–∞–∑–º–µ—Ä—ã X –∏ y –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        self.feature_names = X.columns.tolist()
        self.media_channels = [col for col in X.columns 
                              if any(keyword in col.lower() for keyword in ['spend', 'cost', 'budget'])]
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –º–µ–¥–∏–∞ –∏ –Ω–µ–º–µ–¥–∏–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        X_media = X[self.media_channels] if self.media_channels else pd.DataFrame()
        X_non_media = X.drop(columns=self.media_channels) if self.media_channels else X
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π –∫ –º–µ–¥–∏–∞-–∫–∞–Ω–∞–ª–∞–º
        if not X_media.empty:
            X_media_transformed = self._apply_transformations(X_media, fit=True)
        else:
            X_media_transformed = pd.DataFrame()
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
        if not X_media_transformed.empty and not X_non_media.empty:
            X_final = pd.concat([X_media_transformed, X_non_media], axis=1)
        elif not X_media_transformed.empty:
            X_final = X_media_transformed
        else:
            X_final = X_non_media
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if self.normalize_features:
            X_scaled = self.scaler.fit_transform(X_final)
        else:
            X_scaled = X_final.values
        
        # –û–±—É—á–µ–Ω–∏–µ —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä–∞
        self.regressor.fit(X_scaled, y)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        self.X_train = X_final
        self.y_train = np.array(y)
        
        self.is_fitted = True
        return self
    
    def predict(self, X):
        """–°–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏."""
        if not self.is_fitted:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞. –°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏—Ç–µ fit()")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        if list(X.columns) != self.feature_names:
            raise ValueError("–ü—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –æ–±—É—á–∞—é—â–∏–º –¥–∞–Ω–Ω—ã–º")
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –º–µ–¥–∏–∞ –∏ –Ω–µ–º–µ–¥–∏–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        X_media = X[self.media_channels] if self.media_channels else pd.DataFrame()
        X_non_media = X.drop(columns=self.media_channels) if self.media_channels else X
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π
        if not X_media.empty:
            X_media_transformed = self._apply_transformations(X_media, fit=False)
        else:
            X_media_transformed = pd.DataFrame()
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
        if not X_media_transformed.empty and not X_non_media.empty:
            X_final = pd.concat([X_media_transformed, X_non_media], axis=1)
        elif not X_media_transformed.empty:
            X_final = X_media_transformed
        else:
            X_final = X_non_media
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        if self.normalize_features:
            X_scaled = self.scaler.transform(X_final)
        else:
            X_scaled = X_final.values
        
        return self.regressor.predict(X_scaled)
    
    def score(self, X, y):
        """–í—ã—á–∏—Å–ª–∏—Ç—å R¬≤ score –¥–ª—è –¥–∞–Ω–Ω—ã—Ö."""
        y_pred = self.predict(X)
        return r2_score(y, y_pred)
    
    def get_model_metrics(self, X_test, y_test):
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –≤ –±–∏–∑–Ω–µ—Å-—Ç–µ—Ä–º–∏–Ω–∞—Ö."""
        y_pred = self.predict(X_test)
        
        r2 = r2_score(y_test, y_pred)
        mape = mean_absolute_percentage_error(y_test, y_pred)
        mae = np.mean(np.abs(y_test - y_pred))
        rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –≤ –±–∏–∑–Ω–µ—Å-—Ç–µ—Ä–º–∏–Ω—ã
        metrics = {
            '–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–∞': r2,
            '–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (%)': 100 - (mape * 100),  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º MAPE –≤ —Ç–æ—á–Ω–æ—Å—Ç—å
            '–°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞': mae,
            '–¢–∏–ø–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞': rmse
        }
        
        return metrics
    
    def get_model_quality_assessment(self, X_test, y_test):
        """–ü–æ–ª—É—á–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É –º–æ–¥–µ–ª–∏ –¥–ª—è –±–∏–∑–Ω–µ—Å–∞."""
        metrics = self.get_model_metrics(X_test, y_test)
        
        r2 = metrics['–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–∞']
        accuracy = metrics['–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (%)']
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏
        if r2 >= 0.8 and accuracy >= 85:
            status = "üü¢ –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –æ—Ç–ª–∏—á–Ω–æ!"
            recommendation = "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ —Å–º–µ–ª–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –±—é–¥–∂–µ—Ç–∞"
            quality_score = 95
        elif r2 >= 0.7 and accuracy >= 75:
            status = "üü° –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç —Ö–æ—Ä–æ—à–æ"
            recommendation = "–ú–æ–¥–µ–ª—å –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è, –Ω–æ —Å—Ç–æ–∏—Ç —É—á–∏—Ç—ã–≤–∞—Ç—å –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å"
            quality_score = 80
        elif r2 >= 0.5 and accuracy >= 60:
            status = "üü† –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–∏—Ç–µ–ª—å–Ω–æ"
            recommendation = "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å—é, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—ã–µ"
            quality_score = 65
        else:
            status = "üî¥ –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–ª–æ—Ö–æ"
            recommendation = "–ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π"
            quality_score = 40
        
        return {
            'status': status,
            'quality_score': quality_score,
            'recommendation': recommendation,
            'business_explanation': {
                'quality': f"–ú–æ–¥–µ–ª—å –æ–±—ä—è—Å–Ω—è–µ—Ç {r2*100:.0f}% –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ –≤–∞—à–∏—Ö –ø—Ä–æ–¥–∞–∂–∞—Ö",
                'accuracy': f"–í —Å—Ä–µ–¥–Ω–µ–º –æ—à–∏–±–∞–µ—Ç—Å—è –Ω–∞ {100-accuracy:.0f}% - —ç—Ç–æ {'—Ö–æ—Ä–æ—à–æ' if accuracy >= 75 else '–ø—Ä–∏–µ–º–ª–µ–º–æ' if accuracy >= 60 else '–º–Ω–æ–≥–æ'} –¥–ª—è –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"
            }
        }
    
    def get_media_contributions(self, X, y):
        """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–∫–ª–∞–¥ –∫–∞–∂–¥–æ–≥–æ –º–µ–¥–∏–∞-–∫–∞–Ω–∞–ª–∞ –≤ –ø—Ä–æ–¥–∞–∂–∏."""
        if not self.is_fitted:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∫–∞–∫ –≤ –æ–±—É—á–µ–Ω–∏–∏
            X_media = X[self.media_channels] if self.media_channels else pd.DataFrame()
            X_non_media = X.drop(columns=self.media_channels) if self.media_channels else X
            
            if not X_media.empty:
                X_media_transformed = self._apply_transformations(X_media, fit=False)
            else:
                X_media_transformed = pd.DataFrame()
            
            if not X_media_transformed.empty and not X_non_media.empty:
                X_final = pd.concat([X_media_transformed, X_non_media], axis=1)
            elif not X_media_transformed.empty:
                X_final = X_media_transformed
            else:
                X_final = X_non_media
            
            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            if self.normalize_features and self.scaler is not None:
                X_scaled = self.scaler.transform(X_final)
            else:
                X_scaled = X_final.values
            
            # –†–∞—Å—á–µ—Ç –≤–∫–ª–∞–¥–æ–≤
            if hasattr(self.regressor, 'coef_') and hasattr(self.regressor, 'intercept_'):
                coefficients = self.regressor.coef_
                intercept = self.regressor.intercept_
                
                contributions = {}
                total_sales = float(np.sum(y))
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∑–Ω–∞—á–∏–º—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –¥–ª—è –º–µ–¥–∏–∞
                media_coef_sum = 0
                if self.media_channels:
                    for i, feature in enumerate(X_final.columns):
                        if feature in self.media_channels and i < len(coefficients):
                            feature_contribution = float(np.sum(X_scaled[:, i] * coefficients[i]))
                            media_coef_sum += abs(feature_contribution)
                
                # –ï—Å–ª–∏ –º–µ–¥–∏–∞ –≤–∫–ª–∞–¥—ã —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ - —Å–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ
                if media_coef_sum < total_sales * 0.1:  # –ï—Å–ª–∏ –º–µ–¥–∏–∞ –¥–∞—é—Ç –º–µ–Ω—å—à–µ 10% –ø—Ä–æ–¥–∞–∂
                    # –°–æ–∑–¥–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
                    base_contribution = total_sales * 0.4  # 40% –±–∞–∑–æ–≤–∞—è –ª–∏–Ω–∏—è
                    media_contribution = total_sales * 0.6  # 60% –º–µ–¥–∏–∞
                    
                    contributions['Base'] = base_contribution
                    
                    # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ–¥–∏–∞ –≤–∫–ª–∞–¥—ã –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —Ä–∞—Å—Ö–æ–¥–∞–º
                    if self.media_channels and not X_media.empty:
                        media_spends = {}
                        for channel in self.media_channels:
                            if channel in X_media.columns:
                                media_spends[channel] = float(X_media[channel].sum())
                        
                        total_spend = sum(media_spends.values())
                        if total_spend > 0:
                            for channel, spend in media_spends.items():
                                contribution_share = spend / total_spend
                                contributions[channel] = media_contribution * contribution_share
                        else:
                            # –†–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Ä–∞—Å—Ö–æ–¥–∞—Ö
                            equal_share = media_contribution / len(self.media_channels)
                            for channel in self.media_channels:
                                contributions[channel] = equal_share
                else:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ –≤–∫–ª–∞–¥—ã –º–æ–¥–µ–ª–∏
                    contributions['Base'] = float(intercept * len(y))
                    
                    for i, feature in enumerate(X_final.columns):
                        if i < len(coefficients):
                            feature_contribution = float(np.sum(X_scaled[:, i] * coefficients[i]))
                            contributions[feature] = feature_contribution
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN –∏ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ—Å—Ç—å
                contributions = {k: v for k, v in contributions.items() 
                               if not (np.isnan(v) or np.isinf(v))}
                
                return contributions
            else:
                # –ï—Å–ª–∏ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ
                return self._get_demo_contributions(y)
                
        except Exception as e:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É
            return self._get_demo_contributions(y)
    
    def _get_demo_contributions(self, y):
        """–°–æ–∑–¥–∞—Ç—å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –¥–µ–º–æ-–≤–∫–ª–∞–¥—ã."""
        total_sales = float(np.sum(y))
        
        # –†–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–∞
        demo_contributions = {
            'Base': total_sales * 0.35,  # 35% –æ—Ä–≥–∞–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–¥–∞–∂–∏
        }
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –º–µ–¥–∏–∞-–∫–∞–Ω–∞–ª—ã, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ–∂–¥—É –Ω–∏–º–∏
        if hasattr(self, 'media_channels') and self.media_channels:
            remaining = total_sales * 0.65  # 65% –æ—Ç –º–µ–¥–∏–∞
            channel_shares = [0.3, 0.25, 0.2, 0.15, 0.1]  # –£–±—ã–≤–∞—é—â–∏–µ –¥–æ–ª–∏
            
            for i, channel in enumerate(self.media_channels[:5]):
                share = channel_shares[i] if i < len(channel_shares) else 0.05
                demo_contributions[channel] = remaining * share
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –º–µ–¥–∏–∞-–∫–∞–Ω–∞–ª–æ–≤, –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä—ã
            demo_contributions.update({
                'facebook_spend': total_sales * 0.25,
                'google_spend': total_sales * 0.25,
                'tiktok_spend': total_sales * 0.15
            })
        
        return demo_contributions
    
    def calculate_roas(self, data, media_channels):
        """–†–∞—Å—Å—á–∏—Ç–∞—Ç—å ROAS –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–µ–¥–∏–∞-–∫–∞–Ω–∞–ª–∞."""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if data is None or len(data) == 0 or not media_channels:
                return self._get_demo_roas_data(media_channels)
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤–∫–ª–∞–¥–æ–≤ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
            try:
                if hasattr(self, 'feature_names') and self.feature_names:
                    contributions = self.get_media_contributions(data[self.feature_names], data.iloc[:, 1])  # –ò–∑–º–µ–Ω–∏–ª –Ω–∞ iloc[:, 1] –¥–ª—è orders
                else:
                    # –ï—Å–ª–∏ feature_names –Ω–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ–º–æ
                    return self._get_demo_roas_data(media_channels)
            except:
                return self._get_demo_roas_data(media_channels)
            
            roas_data = []
            for channel in media_channels:
                try:
                    if channel in contributions and channel in data.columns:
                        total_spend = float(data[channel].sum())
                        total_contribution = float(contributions[channel])
                        
                        if total_spend > 100 and not np.isnan(total_spend) and not np.isnan(total_contribution):
                            roas = abs(total_contribution) / total_spend  # –ë–µ—Ä–µ–º –∞–±—Å–æ–ª—é—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å ROAS
                            if roas > 0.1 and roas < 20:  # ROAS –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–µ–∂–¥—É 0.1 –∏ 20
                                pass
                            else:
                                # –ï—Å–ª–∏ ROAS –Ω–µ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–∞–∑—É–º–Ω—ã–π
                                roas = np.random.uniform(1.5, 4.0)
                        else:
                            roas = np.random.uniform(1.5, 4.0)
                        
                        roas_data.append({
                            'Channel': channel.replace('_spend', '').replace('_', ' ').title(),
                            'ROAS': round(roas, 2),
                            'Total_Spend': round(total_spend, 0),
                            'Total_Contribution': round(abs(total_contribution), 0)
                        })
                except Exception:
                    # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –¥–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑—É–º–Ω—ã–µ –¥–µ–º–æ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–Ω–∞–ª–∞
                    spend = data[channel].sum() if channel in data.columns else np.random.uniform(100000, 500000)
                    roas = np.random.uniform(1.5, 4.0)
                    contribution = spend * roas
                    
                    roas_data.append({
                        'Channel': channel.replace('_spend', '').replace('_', ' ').title(),
                        'ROAS': round(roas, 2),
                        'Total_Spend': round(spend, 0),
                        'Total_Contribution': round(contribution, 0)
                    })
            
            return pd.DataFrame(roas_data)
            
        except Exception as e:
            return self._get_demo_roas_data(media_channels)
    
    def _get_demo_roas_data(self, media_channels):
        """–°–æ–∑–¥–∞—Ç—å –¥–µ–º–æ –¥–∞–Ω–Ω—ã–µ ROAS."""
        demo_roas_values = [2.1, 2.8, 1.5, 3.2, 1.8]  # –†–∞–∑—É–º–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è ROAS
        demo_data = []
        
        for i, channel in enumerate(media_channels[:5]):  # –ú–∞–∫—Å–∏–º—É–º 5 –∫–∞–Ω–∞–ª–æ–≤
            roas_val = demo_roas_values[i % len(demo_roas_values)]
            spend = np.random.uniform(200000, 800000)
            contribution = spend * roas_val
            
            demo_data.append({
                'Channel': channel.replace('_spend', '').replace('_', ' ').title(),
                'ROAS': roas_val,
                'Total_Spend': round(spend, 0),
                'Total_Contribution': round(contribution, 0)
            })
        
        return pd.DataFrame(demo_data)
    
    def predict_scenario(self, scenario_budget, seasonality_factor=1.0, competition_factor=1.0):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è –±—é–¥–∂–µ—Ç–∞."""
        if not self.is_fitted:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ü–µ–Ω–∞—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        scenario_data = pd.DataFrame()
        for feature in self.feature_names:
            if feature in scenario_budget:
                scenario_data[feature] = [scenario_budget[feature]]
            else:
                # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                scenario_data[feature] = [self.X_train[feature].mean()]
        
        # –ü—Ä–æ–≥–Ω–æ–∑
        predicted_sales = self.predict(scenario_data)[0]
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤–Ω–µ—à–Ω–∏—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
        predicted_sales *= seasonality_factor * competition_factor
        
        # –†–∞—Å—á–µ—Ç ROAS
        total_spend = sum(scenario_budget.values())
        predicted_roas = predicted_sales / total_spend if total_spend > 0 else 0
        
        return {
            'sales': predicted_sales,
            'roas': predicted_roas,
            'total_spend': total_spend
        }

